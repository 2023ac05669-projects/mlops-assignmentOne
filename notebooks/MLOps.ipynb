{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a09c344-fc02-40c2-b897-13adc46ff9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade mlflow\n",
    "!pip install -U scikit-learn pandas joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0838509e-6333-4588-ad9e-ee8dc7cc4739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts will be stored in: c:\\Users\\kushl\\Documents\\MLOpsAssignment\\mlops-assignmentOne\\notebooks\\models\\BestModel\n",
      "Data loaded and preprocessed successfully.\n",
      "Tracking URI: file:///C:/Users/kushl/Documents/MLOpsAssignment/mlops-assignmentOne/notebooks/mlruns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kushl\\anaconda3\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2025/08/10 18:30:21 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logicstic Regression:\n",
      "RMSE: 0.7456\n",
      "R² Score: 0.5758\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f94b63c7274092a2e3fc494ec393e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'LogisticRegression' already exists. Creating a new version of this model...\n",
      "Created version '3' of model 'LogisticRegression'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside run with id : 572c79f1eced4549946ada600726c081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kushl\\anaconda3\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2025/08/10 18:30:26 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Decision Tree Regressor:\n",
      "RMSE: 0.6446\n",
      "R² Score: 0.6829\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d7ac4110ef463abd9dfc233ead60b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'DecisionTreeRegression' already exists. Creating a new version of this model...\n",
      "Created version '3' of model 'DecisionTreeRegression'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside run with id : 56a3c8958e0e4c06bedbb94fb9f67e5a\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "import os\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models.signature import infer_signature\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create artifact repository\n",
    "REPO_ROOT = Path.cwd()\n",
    "MODELS_DIR = REPO_ROOT / \"models/BestModel\"\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DATA_DIR_RAW = REPO_ROOT  / \"data/raw\"\n",
    "DATA_DIR_RAW.mkdir(parents=True, exist_ok=True)\n",
    "DATA_DIR_PROCESSED = REPO_ROOT / \"data/processed\"\n",
    "DATA_DIR_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Artifacts will be stored in: {MODELS_DIR}\")\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(DATA_DIR_RAW / \"california_housing_raw.csv\")\n",
    "#df = housing.frame\n",
    "\n",
    "# Preprocessing\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df.drop(\"MedHouseVal\", axis=1))\n",
    "\n",
    "# Create processed DataFrame\n",
    "df_processed = pd.DataFrame(scaled_features, columns=df.drop(\"MedHouseVal\", axis=1).columns)\n",
    "df_processed[\"MedHouseVal\"] = df[\"MedHouseVal\"]\n",
    "\n",
    "# Save raw and processed datasets\n",
    "df.to_csv(DATA_DIR_RAW / \"california_housing_raw.csv\", index=False)\n",
    "df_processed.to_csv(DATA_DIR_PROCESSED / \"california_housing_processed.csv\", index=False)\n",
    "\n",
    "print(\"Data loaded and preprocessed successfully.\")\n",
    "\n",
    "\n",
    "X = df.drop(\"MedHouseVal\", axis=1)\n",
    "y = df[\"MedHouseVal\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "mlruns_path = (REPO_ROOT / \"mlruns\").resolve()\n",
    "mlruns_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Use a proper file URI\n",
    "mlflow.set_tracking_uri(mlruns_path.as_uri()) \n",
    "\n",
    "\n",
    "# Check and create default experiment if needed\n",
    "if not mlflow.get_experiment_by_name(\"Default\"):\n",
    "    mlflow.create_experiment(name=\"Default\")\n",
    "# ------------------------\n",
    "# Linear Regression - MLflow Run\n",
    "# ------------------------\n",
    "\n",
    "# Check where it's tracking\n",
    "print(\"Tracking URI:\", mlflow.get_tracking_uri())\n",
    "\n",
    "mlflow.set_experiment(\"LogisticRegressionExperiment\")\n",
    "with mlflow.start_run(run_name=\"LogisticRegressionExperiment\") as lr_run:\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    lr_preds = lr_model.predict(X_test)\n",
    "\n",
    "    input_example = X_test.sample(5)\n",
    "    predicted = lr_model.predict(input_example)\n",
    "\n",
    "    # Infer model signature\n",
    "    signature = infer_signature(input_example, predicted)\n",
    "\n",
    "\n",
    "    lr_rmse = np.sqrt(mean_squared_error(y_test, lr_preds))  # default squared=True\n",
    "    lr_r2 = r2_score(y_test, lr_preds)\n",
    "\n",
    "    print(\"Logicstic Regression:\")\n",
    "    print(f\"RMSE: {lr_rmse:.4f}\")\n",
    "    print(f\"R² Score: {lr_r2:.4f}\")\n",
    "\n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(lr_model, artifact_path=\"LogisticRegression\", input_example=input_example, signature=signature,  registered_model_name=\"LogisticRegression\")\n",
    "\n",
    "    print(f\"inside run with id : {lr_run.info.run_id}\")\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"rmse\", lr_rmse)\n",
    "    mlflow.log_metric(\"r2\", lr_r2)\n",
    "\n",
    "# ------------------------\n",
    "# Decision Tree - MLflow Run\n",
    "# ------------------------\n",
    "mlflow.set_experiment(\"DecisionTreeExperiment\")\n",
    "with mlflow.start_run(run_name=\"DecisionTreeExperiment\") as dt_run:\n",
    "    dt_model = DecisionTreeRegressor(random_state=42, max_depth=10)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    dt_preds = dt_model.predict(X_test)\n",
    "\n",
    "    dt_rmse = np.sqrt(mean_squared_error(y_test, dt_preds))\n",
    "    dt_r2 = r2_score(y_test, dt_preds)\n",
    "\n",
    "    input_example = X_test.sample(5)\n",
    "    predicted = dt_model.predict(input_example)\n",
    "\n",
    "    # Infer model signature\n",
    "    signature = infer_signature(input_example, predicted)\n",
    "\n",
    "    print(\"\\n Decision Tree Regressor:\")\n",
    "    print(f\"RMSE: {dt_rmse:.4f}\")\n",
    "    print(f\"R² Score: {dt_r2:.4f}\")\n",
    "\n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(dt_model, artifact_path=\"DecisionTreeRegression\", input_example=input_example, signature=signature,  registered_model_name=\"DecisionTreeRegression\")\n",
    "\n",
    "    print(f\"inside run with id : {dt_run.info.run_id}\")\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"rmse\", dt_rmse)\n",
    "    mlflow.log_metric(\"r2\", dt_r2)\n",
    "\n",
    "\n",
    "def dumpModel(model_var_list):\n",
    "    #model_var_list=list(model)\n",
    "    # Save model locally\n",
    "    joblib.dump(model_var_list[0], MODELS_DIR / \"betterModel.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "dt_modelparams=[dt_model, dt_rmse, dt_r2, dt_run]\n",
    "lr_modelparams=[lr_model, lr_rmse, lr_r2, lr_run]\n",
    "\n",
    "\n",
    "#Choose best model based on rmse and r2 values\n",
    "\n",
    "if dt_rmse < lr_rmse and dt_r2 > lr_r2:\n",
    "    better_model = dt_modelparams\n",
    "elif lr_rmse < dt_rmse and lr_r2 > dt_r2:\n",
    "    better_model = lr_modelparams\n",
    "elif dt_r2 > lr_r2:\n",
    "    better_model = dt_modelparams\n",
    "else:\n",
    "    better_model = lr_modelparams   \n",
    "\n",
    "#dumping model and registering model\n",
    "\n",
    "dumpModel(better_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde431d3-2842-49b0-9399-c18e5ad555b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9454cd49-16f6-49ac-aa88-922f86198e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
